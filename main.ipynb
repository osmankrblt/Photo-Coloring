{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from numba import jit,cuda\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "import pickle as pkl\n",
    "from tensorflow.keras.utils import array_to_img, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, xyz2lab\n",
    "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten,MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from skimage.io import imsave\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n%%cmd\\npip install wandb\\npip install scikit-image\\npip install skimage\\npip install numba\\npip install keras-unet\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "%%cmd\n",
    "pip install wandb\n",
    "pip install scikit-image\n",
    "pip install skimage\n",
    "pip install numba\n",
    "pip install keras-unet\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_list =os.listdir(\"data/train/\")\n",
    "test_images_list = os.listdir(\"data/test/\")\n",
    "\n",
    "random.shuffle(train_images_list)\n",
    "random.shuffle(test_images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImageColorful = list(map(lambda x : \"data/train/\"+x ,train_images_list[0:6000]))\n",
    "testImageColorful = list(map(lambda x : \"data/test/\"+x ,test_images_list[0:500]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainImageColorful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_to_gray_lab(img):\n",
    "    img = cv2.resize(cv2.imread(img),(400,400))\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    #img = img_to_array(load_img(img))\n",
    "    img = rgb2lab(img/255)\n",
    "    img = img[:,:,0]\n",
    "    img = img.reshape(400, 400, 1)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def preprocess_image_to_lab(img):\n",
    "    img = cv2.resize(cv2.imread(img),(400,400))\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    #img = img_to_array(load_img(img))\n",
    "    img = rgb2lab(img/255)\n",
    "    img = img[:,:,1:]\n",
    "    img /= 128\n",
    "    img = img.reshape(400, 400, 2)\n",
    "\n",
    "    return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/train/3983980965.jpg'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainImageColorful[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process test image - 0\n",
      "Process test image - 100\n",
      "Process test image - 200\n",
      "Process test image - 300\n",
      "Process test image - 400\n",
      "Time taken in seconds =  83.92048668861389\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "testX={}\n",
    "testY={}\n",
    "\n",
    "\n",
    "for ix,img in enumerate(testImageColorful):\n",
    "    \n",
    "\n",
    "   \n",
    "    testX[img.split(\"/\")[2][:-4]] = preprocess_image_to_gray_lab(img)\n",
    "    testY[img.split(\"/\")[2][:-4]] = preprocess_image_to_lab(img)\n",
    " \n",
    "\n",
    "    if ix%100==0:\n",
    "        print(\"Process test image - \"+str(ix))\n",
    "\n",
    "print(\"Time taken in seconds = \", time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickles/process_test_imagesX.pkl\",\"wb\") as process_pickle:\n",
    "    pkl.dump(testX,process_pickle)\n",
    "with open(\"pickles/process_test_imagesY.pkl\",\"wb\") as process_pickle:\n",
    "    pkl.dump(testY,process_pickle)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickles/process_test_imagesX.pkl\",\"rb\") as f:\n",
    "    testX = pkl.load(f)\n",
    "with open(\"pickles/process_test_imagesY.pkl\",\"rb\") as f:\n",
    "    testY = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process image - 0\n",
      "Process image - 100\n",
      "Process image - 200\n",
      "Process image - 300\n",
      "Process image - 400\n",
      "Process image - 500\n",
      "Process image - 600\n",
      "Process image - 700\n",
      "Process image - 800\n",
      "Process image - 900\n",
      "Process image - 1000\n",
      "Process image - 1100\n",
      "Process image - 1200\n",
      "Process image - 1300\n",
      "Process image - 1400\n",
      "Process image - 1500\n",
      "Process image - 1600\n",
      "Process image - 1700\n",
      "Process image - 1800\n",
      "Process image - 1900\n",
      "Process image - 2000\n",
      "Process image - 2100\n",
      "Process image - 2200\n",
      "Process image - 2300\n",
      "Process image - 2400\n",
      "Process image - 2500\n",
      "Process image - 2600\n",
      "Process image - 2700\n",
      "Process image - 2800\n",
      "Process image - 2900\n",
      "Process image - 3000\n",
      "Process image - 3100\n",
      "Process image - 3200\n",
      "Process image - 3300\n",
      "Process image - 3400\n",
      "Process image - 3500\n",
      "Process image - 3600\n",
      "Process image - 3700\n",
      "Process image - 3800\n",
      "Process image - 3900\n",
      "Process image - 4000\n",
      "Process image - 4100\n",
      "Process image - 4200\n",
      "Process image - 4300\n",
      "Process image - 4400\n",
      "Process image - 4500\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "trainX={}\n",
    "trainY={}\n",
    "\n",
    "\n",
    "for ix, img in enumerate(trainImageColorful):\n",
    "    \n",
    "    img=trainImageColorful[ix]\n",
    "   \n",
    "    \n",
    "    trainX[img.split(\"/\")[2][:-4]] = preprocess_image_to_gray_lab(img)\n",
    "    trainY[img.split(\"/\")[2][:-4]] = preprocess_image_to_lab(img)\n",
    "   \n",
    " \n",
    "\n",
    "    if ix%100==0:\n",
    "        print(\"Process image - \"+str(ix))\n",
    "\n",
    "print(\"Time taken in seconds = \", time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mpickles/process_train_imagesX.pkl\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m process_pickle:\n\u001b[1;32m----> 2\u001b[0m     pkl\u001b[39m.\u001b[39;49mdump(trainX,process_pickle)\n\u001b[0;32m      3\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mpickles/process_train_imagesY.pkl\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m process_pickle:\n\u001b[0;32m      4\u001b[0m     pkl\u001b[39m.\u001b[39mdump(trainY,process_pickle)\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open(\"pickles/process_train_imagesX.pkl\",\"wb\") as process_pickle:\n",
    "    pkl.dump(trainX,process_pickle)\n",
    "with open(\"pickles/process_train_imagesY.pkl\",\"wb\") as process_pickle:\n",
    "    pkl.dump(trainY,process_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX={}\n",
    "trainY={}\n",
    "\n",
    "with open(\"pickles/process_train_imagesX.pkl\",\"rb\") as f:\n",
    "    trainX = pkl.load(f)\n",
    "\n",
    "with open(\"pickles/process_train_imagesY.pkl\",\"rb\") as f:\n",
    "    trainY = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_data_generator(trainX,trainY,trainImageColorful,num_photos_per_batch):\n",
    "    \n",
    "    X, y = [], []\n",
    "\n",
    "    n = 0\n",
    "\n",
    "    while True:\n",
    "\n",
    "        for key in trainImageColorful:\n",
    "            n +=1\n",
    "\n",
    "            photo = trainX[key.split(\"/\")[2][:-4]]\n",
    "\n",
    "            photoColor = trainY[key.split(\"/\")[2][:-4]]\n",
    "\n",
    "          \n",
    "          \n",
    "                \n",
    "            X.append(photo)\n",
    "                   \n",
    "            y.append(photoColor)\n",
    "         \n",
    "\n",
    "            if n==num_photos_per_batch:\n",
    "                u = np.array(X)\n",
    "                w = np.array(y)\n",
    "            \n",
    "             \n",
    "               \n",
    "                yield(u,w)\n",
    "                \n",
    "                X,  y = [], []\n",
    "                n = 0\n",
    "def valid_data_generator(validX,validY,validImageColorful,num_photos_per_batch):\n",
    "    \n",
    "    X, y = [], []\n",
    "\n",
    "    n = 0\n",
    "\n",
    "    while True:\n",
    "\n",
    "        for key in validImageColorful:\n",
    "            n +=1\n",
    "\n",
    "            photo = validX[key.split(\"/\")[2][:-4]]\n",
    "\n",
    "            photoColor = validY[key.split(\"/\")[2][:-4]]\n",
    "\n",
    "          \n",
    "          \n",
    "                \n",
    "            X.append(photo)\n",
    "                   \n",
    "            y.append(photoColor)\n",
    "         \n",
    "\n",
    "            if n==num_photos_per_batch:\n",
    "                u = np.array(X)\n",
    "                w = np.array(y)\n",
    "            \n",
    "             \n",
    "               \n",
    "                yield(u,w)\n",
    "                \n",
    "                X,  y = [], []\n",
    "                n = 0\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import wandb \n",
    "#wandb.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(400, 400, 1)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same' , strides=2))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same' , strides=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same' ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 200, 200, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 200, 200, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 200, 200, 32)      9248      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 200, 200, 64)      18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 100, 100, 64)      36928     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 100, 100, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 50, 50, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 50, 50, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 50, 50, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 50, 50, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 50, 50, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 50, 50, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 50, 50, 256)       1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 50, 50, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 50, 50, 128)       295040    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 50, 50, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 50, 50, 64)        73792     \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 100, 100, 32)      18464     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 200, 200, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 200, 200, 16)      4624      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 400, 400, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 400, 400, 2)       290       \n",
      "=================================================================\n",
      "Total params: 3,339,122\n",
      "Trainable params: 3,336,498\n",
      "Non-trainable params: 2,624\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',loss='mse' ,metrics=[\n",
    "        \"accuracy\"\n",
    "    ])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "number_pics_per_bath = 10\n",
    "train_steps = len(trainImageColorful)//number_pics_per_bath\n",
    "valid_steps = len(testImageColorful)//number_pics_per_bath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model,load_model\n",
    "model = load_model(\"model_weights\\model_23.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)\n",
    "filepath = \"model_weights/saved-model-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  5/600 [..............................] - ETA: 7:52 - loss: 0.0118 - accuracy: 0.6419"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) Resource exhausted:  MemoryError: Unable to allocate 12.2 MiB for an array with shape (10, 400, 400, 1) and data type float64\nTraceback (most recent call last):\n\n  File \"c:\\Users\\hosma\\anaconda3\\envs\\tensorflowEnv\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"c:\\Users\\hosma\\anaconda3\\envs\\tensorflowEnv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 645, in wrapper\n    return func(*args, **kwargs)\n\n  File \"c:\\Users\\hosma\\anaconda3\\envs\\tensorflowEnv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 892, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"c:\\Users\\hosma\\anaconda3\\envs\\tensorflowEnv\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 822, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\hosma\\AppData\\Local\\Temp\\ipykernel_53180\\3882066652.py\", line 25, in train_data_generator\n    u = np.array(X)\n\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.2 MiB for an array with shape (10, 400, 400, 1) and data type float64\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) Resource exhausted:  MemoryError: Unable to allocate 12.2 MiB for an array with shape (10, 400, 400, 1) and data type float64\nTraceback (most recent call last):\n\n  File \"c:\\Users\\hosma\\anaconda3\\envs\\tensorflowEnv\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"c:\\Users\\hosma\\anaconda3\\envs\\tensorflowEnv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 645, in wrapper\n    return func(*args, **kwargs)\n\n  File \"c:\\Users\\hosma\\anaconda3\\envs\\tensorflowEnv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 892, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"c:\\Users\\hosma\\anaconda3\\envs\\tensorflowEnv\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 822, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\hosma\\AppData\\Local\\Temp\\ipykernel_53180\\3882066652.py\", line 25, in train_data_generator\n    u = np.array(X)\n\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.2 MiB for an array with shape (10, 400, 400, 1) and data type float64\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[IteratorGetNext/_4]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_2641]\n\nFunction call stack:\ntrain_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m train_generator \u001b[39m=\u001b[39m train_data_generator(trainX\u001b[39m=\u001b[39mtrainX,trainY\u001b[39m=\u001b[39mtrainY,trainImageColorful\u001b[39m=\u001b[39mtrainImageColorful,num_photos_per_batch\u001b[39m=\u001b[39mnumber_pics_per_bath)\n\u001b[0;32m      2\u001b[0m valid_generator \u001b[39m=\u001b[39m valid_data_generator(validX\u001b[39m=\u001b[39mtestX,validY\u001b[39m=\u001b[39mtestY,validImageColorful\u001b[39m=\u001b[39mtestImageColorful,num_photos_per_batch\u001b[39m=\u001b[39mnumber_pics_per_bath)\n\u001b[1;32m----> 4\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_generator,epochs\u001b[39m=\u001b[39;49mepochs,steps_per_epoch\u001b[39m=\u001b[39;49mtrain_steps,validation_data\u001b[39m=\u001b[39;49m(valid_generator),validation_steps\u001b[39m=\u001b[39;49mvalid_steps,workers\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,callbacks\u001b[39m=\u001b[39;49m[es,checkpoint])\n",
      "File \u001b[1;32mc:\\Users\\hosma\\anaconda3\\envs\\tensorflowEnv\\lib\\site-packages\\keras\\engine\\training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1178\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1179\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1180\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1181\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1182\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1183\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1184\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1185\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1186\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\hosma\\anaconda3\\envs\\tensorflowEnv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\hosma\\anaconda3\\envs\\tensorflowEnv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:924\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    922\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    923\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 924\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    925\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    926\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    927\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\hosma\\anaconda3\\envs\\tensorflowEnv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   3037\u001b[0m   (graph_function,\n\u001b[0;32m   3038\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   3040\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\hosma\\anaconda3\\envs\\tensorflowEnv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1960\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1961\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1962\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1963\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1964\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1965\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m     args,\n\u001b[0;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1968\u001b[0m     executing_eagerly)\n\u001b[0;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\hosma\\anaconda3\\envs\\tensorflowEnv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    592\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    593\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    594\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    595\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    596\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    597\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\hosma\\anaconda3\\envs\\tensorflowEnv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted:  MemoryError: Unable to allocate 12.2 MiB for an array with shape (10, 400, 400, 1) and data type float64\nTraceback (most recent call last):\n\n  File \"c:\\Users\\hosma\\anaconda3\\envs\\tensorflowEnv\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"c:\\Users\\hosma\\anaconda3\\envs\\tensorflowEnv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 645, in wrapper\n    return func(*args, **kwargs)\n\n  File \"c:\\Users\\hosma\\anaconda3\\envs\\tensorflowEnv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 892, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"c:\\Users\\hosma\\anaconda3\\envs\\tensorflowEnv\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 822, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\hosma\\AppData\\Local\\Temp\\ipykernel_53180\\3882066652.py\", line 25, in train_data_generator\n    u = np.array(X)\n\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.2 MiB for an array with shape (10, 400, 400, 1) and data type float64\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) Resource exhausted:  MemoryError: Unable to allocate 12.2 MiB for an array with shape (10, 400, 400, 1) and data type float64\nTraceback (most recent call last):\n\n  File \"c:\\Users\\hosma\\anaconda3\\envs\\tensorflowEnv\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"c:\\Users\\hosma\\anaconda3\\envs\\tensorflowEnv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 645, in wrapper\n    return func(*args, **kwargs)\n\n  File \"c:\\Users\\hosma\\anaconda3\\envs\\tensorflowEnv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 892, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"c:\\Users\\hosma\\anaconda3\\envs\\tensorflowEnv\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 822, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\hosma\\AppData\\Local\\Temp\\ipykernel_53180\\3882066652.py\", line 25, in train_data_generator\n    u = np.array(X)\n\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.2 MiB for an array with shape (10, 400, 400, 1) and data type float64\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[IteratorGetNext/_4]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_2641]\n\nFunction call stack:\ntrain_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_generator = train_data_generator(trainX=trainX,trainY=trainY,trainImageColorful=trainImageColorful,num_photos_per_batch=number_pics_per_bath)\n",
    "valid_generator = valid_data_generator(validX=testX,validY=testY,validImageColorful=testImageColorful,num_photos_per_batch=number_pics_per_bath)\n",
    " \n",
    "model.fit(train_generator,epochs=epochs,steps_per_epoch=train_steps,validation_data=(valid_generator),validation_steps=valid_steps,workers=-1,verbose=1,callbacks=[es,checkpoint])\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(i,coloring):\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    rows = 1\n",
    "    columns = 2\n",
    "    fig.add_subplot(rows, columns, 1)\n",
    "  \n",
    "    normal = load_img(i,color_mode=\"grayscale\",target_size=(400,400))\n",
    "    plt.imshow(normal, cmap='gray', vmin=0, vmax=255)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Gray image\")\n",
    "    \n",
    "\n",
    "    fig.add_subplot(rows, columns, 2)\n",
    "    \n",
    "  \n",
    "    plt.imshow(coloring)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"AI Colorizing\")\n",
    "\n",
    "def mergeOutput(x,output):\n",
    "    output *= 128\n",
    "  \n",
    "    cur = np.zeros((400, 400, 3))\n",
    "    cur[:,:,0] = x[0][:,:,0]\n",
    "    cur[:,:,1:] = output[0]\n",
    "    return cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in testImageColorful[0:5]:\n",
    "    \n",
    "    x = preprocess_image_to_gray_lab(i)\n",
    "    \n",
    "    x = x.reshape(1,400,400,1)\n",
    "\n",
    "    output = model.predict(x)\n",
    "    \n",
    "    cur = mergeOutput(x,output)\n",
    "    \n",
    "    img = lab2rgb(cur)\n",
    "\n",
    "   \n",
    "    show_images(i,img)\n",
    "\n",
    "   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = preprocess_image_to_gray_lab(\"test images/ataturk3.jpg\")\n",
    "\n",
    "x = x.reshape(1,400,400,1)\n",
    "\n",
    "output = model.predict(x)\n",
    "    \n",
    "cur = mergeOutput(x,output)\n",
    "    \n",
    "img = lab2rgb(cur)\n",
    "\n",
    "   \n",
    "show_images(\"test images/ataturk3.jpg\",img)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('machineLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba0bac22d9eb68f7f5a06ef2e353ac664856aa0e4acc18841217d9d0b0f1928e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
